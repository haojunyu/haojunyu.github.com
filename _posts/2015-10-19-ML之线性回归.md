---
layout:	default
title:	ML之线性回归
category:	[ML, Algorithm]
comments:	true
---
线性回归[Line Regression]估计是我们接触最早的机器学习的算法了，差不过在高中的时候我们就会做一类题：就是给定xy坐标上的一些点（一般是线性的），然后用y=ax+b进行拟合，最后求出一个<a,b>以及y的预测值$\hat{y}$。其中y=ax+b在ML中叫模型，<a,b>叫模型参数，或者特征x的权重，而y就是结果或标签，求解模型的方法叫最小二乘法[Ordinary Least Square Estimation]。本文将结合sklearning详细介绍一下线性回归方法。


## 概念理解
在统计学中，[线性回归][wiki_line_regression]是确定因变量$y$和一个或多个自变量$X$之间线性关系的统计分析方法。当自变量只有一个时叫简单线性回归，当自变量有多个时叫多维线性回归（与多变量线性回归的区别见QA1）。


谈及回归，不可避免的谈到分类，这两个概念很相似，只不过分类的结果是1,2,3这样的离散型，而回归的结果却是连续型。二者都可以用来预测。










## 问题&回答
1. Q：多维线性回归和多变量线性回归的区别  
A：该回答参考[这篇英文博文][multiple_vs_multivariate]。  
    * 差异性  
    该问题和线性没有关系。多维回归是指回归模型拥有一个因变量和多个自变量，而多变量回归是指回归模型拥有多个因变量和多个自变量。二者的区别是在于因变量的个数。
    * 联系  
    多变量回归可以由多个多维回归模型构成。
    * 举例说明  
    多变量回归一般用于解决系数的混合检验问题。比如，你想要知道SAT的各项分数对第一学年和第二学年有什么样的影响。一种方法是运行两个简单回归模型，并且查看系数是否相似;另一种方法是运行一个多变量回归模型，而且这种方式是正规的概率检验方式。虽然系数是一样的，但是后续你可以计算它们的相似度和其他属性等。

## 参考文献
1. [线性回归wiki][wiki_line_regression]
2. [多维线性回归vs多变量线性回归][multiple_vs_multivariate]
1. [机器学习实战][meachine_learning_70]

[wiki_line_regression]:  https://en.wikipedia.org/wiki/Linear_regression
[multiple_vs_multivariate]:  http://www.answers.com/Q/What_is_difference_between_multivariate_regression_and_multipal_regression
[meachine_learning_70]:  http://share.weiyun.com/f33d5770eba223764845beddf0d6bc09
